# 极端多读少写场景下的高效C++自旋读写锁实现

## 项目地址
[适用于极端多读少写的高性能自旋读写锁实](https://github.com/HSLL175848494/SpinReadWriteLock)

## 序言
在并发编程中，`mutex` 等锁机制常用于保护共享数据。当读写操作频率相近时，优化空间通常有限。针对**读远多于写**的场景，**读写锁**可实现多个读者并行访问，从而提升性能。本文则聚焦于`极端多读少写`场景，其中写操作频率极低但同步机制仍不可或缺。传统读写锁在此场景下性能不足，因此我尝试基于原子变量实现高效的自旋读写锁。

## 自旋读写锁V1
```cpp
constexpr long long SPINREADWRITELOCK_MAXREADER = (1LL << 62);

class SpinReadWriteLock
{
private:
	std::atomic<long long> count;

public:

	SpinReadWriteLock()noexcept :count(0) {}

	bool try_lock_read() noexcept
	{
		long long old = count.load(std::memory_order_relaxed);

		while (true)
		{
			if(old < 0)
			return false;

			if(count.compare_exchange_weak(old, old +1, std::memory_order_acquire, std::memory_order_relaxed))
				break;
		}

		return true;
	}

	void lock_read() noexcept
	{
		long long old = count.load(std::memory_order_relaxed);

		while (true)
		{
			while(old < 0)
			{
				std::this_thread::yield();
				old = count.load(std::memory_order_relaxed);
			}

			if(count.compare_exchange_weak(old, old +1, std::memory_order_acquire, std::memory_order_relaxed))
				break;
		}
	}

	void unlock_read() noexcept
	{
		count.fetch_sub(1, std::memory_order_relaxed);
	}

	bool try_lock_write() noexcept
	{
		long long old = 0;
		return count.compare_exchange_strong(old, old - SPINREADWRITELOCK_MAXREADER, std::memory_order_acquire, std::memory_order_relaxed);
	}

	void lock_write() noexcept
	{
		long long old = count.load(std::memory_order_relaxed);

		while (true)
		{
			while(old < 0)
			{
				std::this_thread::yield();
				old = count.load(std::memory_order_relaxed);
			}

			if(count.compare_exchange_weak(old, old - SPINREADWRITELOCK_MAXREADER, std::memory_order_acquire, std::memory_order_relaxed))
				break;
		}

		while(count.load(std::memory_order_relaxed) != -SPINREADWRITELOCK_MAXREADER)
			std::this_thread::yield();
	}

	void unlock_write() noexcept
	{
		count.fetch_add(SPINREADWRITELOCK_MAXREADER, std::memory_order_release);
	}
};
```

在v1版本中我使用单个64位原子变量`count`管理两种状态：

1. **读者计数**：count>0时表示当前读者数量
2. **写者标记**：count<0时表示写者已锁定


**读写上锁/解锁的步骤：**

| 操作         | 步骤                                                                 |
|--------------|----------------------------------------------------------------------|
| **读加锁**   |- 检测写标记（count<0则等待）<br>- CAS增加读者计数（count += 1）                 | 
| **解读锁**   | 原子减少读者计数（count -= 1）                                       |
| **写加锁**   | - 检测写标记（count<0则等待）<br> - CAS设置写标记(count += SPINREADWRITELOCK_MAXREADER)<br>- 等待读者退出 |
| **写解锁**   | 原子移除写标记 (count -= SPINREADWRITELOCK_MAXREADER)               |

极端多读少写情况下，读锁获取仅需1次CAS成功,解锁仅需1次原子减法。**写者优先策略** 确保写操作不被无限延迟(写标记后无法获取读锁）。

## 自旋读写锁V2
V1版本读加锁采用`count.compare_exchange_weak(old, old +1)`方式，读者数量多时易CAS操作容易失败，V2版本则将读锁改为乐观锁实现：

```cpp
void lock_read() noexcept
{
	long long old = count.fetch_add(1, std::memory_order_acquire);

	while (old < 0)
	{
		count.fetch_sub(1, std::memory_order_relaxed);

		while (count.load(std::memory_order_relaxed) < 0)
			std::this_thread::yield();

		old = count.fetch_add(1, std::memory_order_acquire);
	}
}
```
由于写操作极少时 old<0 基本不发生，读锁获取简化为单次add操作。若检测到写者，可通过fetch_sub回退。

## 自旋读写锁V3

V2虽将CAS改为乐观锁，但读操作极频繁时，所有线程竞争单一原子计数器仍会导致性能瓶颈，v3版本则引入了分片机制：

```cpp
constexpr int SPINREADWRITELOCK_MAXSLOTS = 128;
constexpr long long SPINREADWRITELOCK_MAXREADER = (1LL << 62);

static_assert(SPINREADWRITELOCK_MAXSLOTS > 0, "SPINREADWRITELOCK_MAXSLOTS must be > 0");
static_assert(SPINREADWRITELOCK_MAXREADER > 0 && SPINREADWRITELOCK_MAXREADER <= (1LL << 62),
			  "SPINREADWRITELOCK_MAXREADER must be > 0 and <= 2^62");

/**
 * @brief Efficient spin lock based on atomic variables, suitable for scenarios where reads significantly outnumber writes
 */
class SpinReadWriteLock
{
	private:

	class alignas(64) InnerLock
	{
		private:
		std::atomic<long long> count;

		public:

		InnerLock() noexcept :count(0) {}

		void lock_read() noexcept
		{
			long long old = count.fetch_add(1, std::memory_order_acquire);

			while (old < 0)
			{
				count.fetch_sub(1, std::memory_order_relaxed);

				while (count.load(std::memory_order_relaxed) < 0)
					std::this_thread::yield();

				old = count.fetch_add(1, std::memory_order_acquire);
			}
		}

		bool try_lock_read() noexcept
		{
			long long old = count.fetch_add(1, std::memory_order_acquire);

			if (old < 0)
			{
				count.fetch_sub(1, std::memory_order_relaxed);
				return false;
			}

			return true;
		}

		void unlock_read() noexcept
		{
			count.fetch_sub(1, std::memory_order_relaxed);
		}

		void mark_write() noexcept
		{
			count.fetch_sub(SPINREADWRITELOCK_MAXREADER, std::memory_order_relaxed);
		}

		void unmark_write() noexcept
		{
			count.fetch_add(SPINREADWRITELOCK_MAXREADER, std::memory_order_relaxed);
		}

		void unlock_write() noexcept
		{
			count.fetch_add(SPINREADWRITELOCK_MAXREADER, std::memory_order_release);
		}

		bool is_write_ready() noexcept
		{
			return count.load(std::memory_order_relaxed) == -SPINREADWRITELOCK_MAXREADER;
		}
	};

	std::atomic<bool> flag;
	InnerLock rwLocks[SPINREADWRITELOCK_MAXSLOTS];

	thread_local static int localIndex;
	static std::atomic<unsigned int> globalIndex;

	unsigned int get_local_index() noexcept
	{
		if (localIndex != -1)
			return localIndex;
		else
			return	localIndex = globalIndex.fetch_add(1, std::memory_order_relaxed) % SPINREADWRITELOCK_MAXSLOTS;
	}

	bool try_mark_write() noexcept
	{
		bool old = true;

		if (!flag.compare_exchange_strong(old, false, std::memory_order_acquire, std::memory_order_relaxed))
			return false;

		for (int i = 0; i < SPINREADWRITELOCK_MAXSLOTS; ++i)
			rwLocks[i].mark_write();

		return true;
	}

	void mark_write() noexcept
	{
		bool old = true;

		while (!flag.compare_exchange_weak(old, false, std::memory_order_acquire, std::memory_order_relaxed))
		{
			std::this_thread::yield();
			old = true;
		}

		for (int i = 0; i < SPINREADWRITELOCK_MAXSLOTS; ++i)
			rwLocks[i].mark_write();
	}

	void unmark_write() noexcept
	{
		for (int i = 0; i < SPINREADWRITELOCK_MAXSLOTS; ++i)
			rwLocks[i].unmark_write();

		flag.store(true, std::memory_order_relaxed);
	}

	unsigned int ready_count(unsigned int startIndex) noexcept
	{
		for (int i = startIndex; i < SPINREADWRITELOCK_MAXSLOTS; ++i)
		{
			if (!rwLocks[i].is_write_ready())
				return i;
		}

		return SPINREADWRITELOCK_MAXSLOTS;
	}

	public:

	SpinReadWriteLock() noexcept :flag(true) {}

	bool try_lock_read() noexcept
	{
		return rwLocks[get_local_index()].try_lock_read();
	}

	template <typename Rep, typename Period>
	bool try_lock_read_for(const std::chrono::duration<Rep, Period>& timeout) noexcept
	{
		auto absTime = std::chrono::steady_clock::now() + timeout;
		return try_lock_read_until(absTime);
	}

	template <typename Clock, typename Duration>
	bool try_lock_read_until(const std::chrono::time_point<Clock, Duration>& absTime) noexcept
	{
		while (!rwLocks[get_local_index()].try_lock_read())
		{
			auto now = Clock::now();

			if (now >= absTime)
				return false;

			std::this_thread::yield();
		}

		return true;
	}

	void lock_read() noexcept
	{
		rwLocks[get_local_index()].lock_read();
	}

	void unlock_read() noexcept
	{
		rwLocks[get_local_index()].unlock_read();
	}

	bool try_lock_write() noexcept
	{
		if (!try_mark_write())
			return false;

		if (ready_count(0) == SPINREADWRITELOCK_MAXSLOTS)
			return true;
		else
			unmark_write();

		return false;
	}

	template <typename Rep, typename Period>
	bool try_lock_write_for(const std::chrono::duration<Rep, Period>& timeout) noexcept
	{
		auto absTime = std::chrono::steady_clock::now() + timeout;
		return try_lock_write_until(absTime);
	}

	template <typename Clock, typename Duration>
	bool try_lock_write_until(const std::chrono::time_point<Clock, Duration>& absTime) noexcept
	{
		std::chrono::time_point<Clock, Duration> now;

		while (!try_mark_write())
		{
			now = Clock::now();

			if (now >= absTime)
				return false;

			std::this_thread::yield();
		}

		unsigned int nextCheckIndex = 0;

		while ((nextCheckIndex = ready_count(nextCheckIndex)) != SPINREADWRITELOCK_MAXSLOTS)
		{
			now = Clock::now();

			if (now >= absTime)
			{
				unmark_write();
				return false;
			}

			std::this_thread::yield();
		}

		return true;
	}

	void lock_write() noexcept
	{
		mark_write();

		unsigned int nextCheckIndex = 0;

		while ((nextCheckIndex = ready_count(nextCheckIndex)) != SPINREADWRITELOCK_MAXSLOTS)
			std::this_thread::yield();
	}

	void unlock_write() noexcept
	{
		for (int i = 0; i < SPINREADWRITELOCK_MAXSLOTS; ++i)
			rwLocks[i].unlock_write();

		flag.store(true, std::memory_order_release);
	}

	SpinReadWriteLock(const SpinReadWriteLock&) = delete;
	SpinReadWriteLock& operator=(const SpinReadWriteLock&) = delete;
};

std::atomic<unsigned int> SpinReadWriteLock::globalIndex{ 0 };
thread_local int SpinReadWriteLock::localIndex{ -1 };

class ReadLockGuard
{
	private:

	SpinReadWriteLock& lock;

	public:

	explicit ReadLockGuard(SpinReadWriteLock& lock) noexcept : lock(lock)
	{
		lock.lock_read();
	}

	~ReadLockGuard() noexcept
	{
		lock.unlock_read();
	}

	ReadLockGuard(const ReadLockGuard&) = delete;
	ReadLockGuard& operator=(const ReadLockGuard&) = delete;
};

class WriteLockGuard
{
	private:

	SpinReadWriteLock& lock;

	public:

	explicit WriteLockGuard(SpinReadWriteLock& lock) noexcept : lock(lock)
	{
		lock.lock_write();
	}

	~WriteLockGuard() noexcept
	{
		lock.unlock_write();
	}

	WriteLockGuard(const WriteLockGuard&) = delete;
	WriteLockGuard& operator=(const WriteLockGuard&) = delete;
};
```

V3版本采用了**分片机制**解决单一原子变量竞争：通过创建128个独立槽位（`SPINREADWRITELOCK_MAXSLOTS`控制），每个槽位独占缓存行（`alignas(64)`避免伪共享），线程绑定特定槽位进行读计数操作以分散竞争压力。然而该设计存在两项主要缺陷（考虑使用场景往往可以接受）：
- **较高内存占用**：128个槽位配合64字节对齐导致单锁占用8KB内存（可通过调整槽位数优化内存占用，但可能会导致性能下降）
- **较高写延迟**：获取写锁需锁定所有槽位并等待所有读者退出，解锁需要移除所有槽位的写标记

## 性能测试  

测试配置：8个读线程（每线程执行1,250,000次获取/释放读锁操作），10次测试平均吞吐量  
（注：测试场景不包含写操作，符合锁设计目标）  

| 锁类型               | 吞吐量 (百万操作/秒) | 相对性能提升 (基准: std::shared_mutex) |  
|----------------------|---------------------|----------------------------------------|  
| std::shared_mutex  | 16.6646            | 1.00x (基准)                          |  
| SpinReadWriteLock v1 | 25.7622            | 1.55x                                 |  
| SpinReadWriteLock v2 | 45.2778            | 2.72x                                 |  
| **SpinReadWriteLock v3** | **405.958**       | **24.36x**                            |  


## 测试环境  
| 组件         | 规格说明                         |  
|--------------|----------------------------------|  
| 编译器       | MSVC v143 x64                    |  
| 优化选项     | /O2 (最大速度优化)             |  
| CPU          | Intel i7-11800H (8核/16线程)     |  
| 基础频率     | 2.3 GHz                          |  
| 操作系统     | Windows 10/11 x64 (Build 19045.5737) |  